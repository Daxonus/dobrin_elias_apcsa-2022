{\rtf1\ansi\ansicpg1252\cocoartf2580
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;\f1\fswiss\fcharset0 Helvetica-Bold;\f2\fswiss\fcharset0 Helvetica;
}
{\colortbl;\red255\green255\blue255;\red15\green112\blue1;\red255\green255\blue254;\red25\green25\blue25;
\red255\green255\blue255;\red0\green0\blue0;\red157\green0\blue210;\red0\green0\blue255;\red32\green108\blue135;
\red101\green76\blue29;\red0\green0\blue109;\red19\green120\blue72;\red144\green1\blue18;}
{\*\expandedcolortbl;;\cssrgb\c0\c50196\c0;\cssrgb\c100000\c100000\c99608;\cssrgb\c12941\c12941\c12941;
\cssrgb\c100000\c100000\c100000;\cssrgb\c0\c0\c0;\cssrgb\c68627\c0\c85882;\cssrgb\c0\c0\c100000;\cssrgb\c14902\c49804\c60000;
\cssrgb\c47451\c36863\c14902;\cssrgb\c0\c6275\c50196;\cssrgb\c3529\c53333\c35294;\cssrgb\c63922\c8235\c8235;}
\margl1440\margr1440\vieww22600\viewh8580\viewkind0
\deftab720
\pard\pardeftab720\sl380\partightenfactor0

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
#Single perceptron for 2-input logic functions AND, OR, NAND\
\pard\pardeftab720\partightenfactor0

\f1\b\fs32 \cf4 \cb5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Copyright: \'a9 NexStream Technical Institute, LLC
\f2\b0 .\
All rights reserved\
\

\f0\fs28 \cf6 \cb1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \
\pard\pardeftab720\sl380\partightenfactor0
\cf7 \cb3 import\cf6  numpy \cf7 as\cf6  np\cb1 \
\
\pard\pardeftab720\sl380\partightenfactor0
\cf8 \cb3 class\cf6  \cf9 Perceptron\cf6 (\cf9 object\cf6 ):\cb1 \
\
\pard\pardeftab720\sl380\partightenfactor0
\cf6 \cb3     \cf8 def\cf6  \cf10 __init__\cf6 (\cf11 self\cf6 , \cf11 no_of_inputs\cf6 , \cf11 threshold\cf6 =\cf12 100\cf6 , \cf11 learning_rate\cf6 =\cf12 0.01\cf6 ):\cb1 \
\cb3         \cf11 self\cf6 .threshold = threshold\cb1 \
\cb3         \cf11 self\cf6 .learning_rate = learning_rate\cb1 \
\cb3         \cf11 self\cf6 .weights = np.zeros(no_of_inputs)\cb1 \
\cb3         \cf11 self\cf6 .bias = \cf12 0\cf6 \cb1 \
\cb3         \cf10 print\cf6 (\cf13 'Initial weights: '\cf6 , \cf11 self\cf6 .weights)\cb1 \
\cb3         \cf10 print\cf6 (\cf13 'Initial bias: '\cf6 , \cf11 self\cf6 .bias)\cb1 \
\cb3         \cf10 print\cf6 (\cf13 'Threshold: '\cf6 , \cf11 self\cf6 .threshold)\cb1 \
\cb3         \cf10 print\cf6 (\cf13 'Learning rate: '\cf6 , \cf11 self\cf6 .learning_rate, \cf13 '\\n'\cf6 )\cb1 \
\
\cb3     \cf8 def\cf6  \cf10 predict\cf6 (\cf11 self\cf6 , \cf11 inputs\cf6 ):\cb1 \
\cb3         z = np.dot(inputs, \cf11 self\cf6 .weights) + \cf11 self\cf6 .bias\cb1 \
\cb3         \cf10 print\cf6 (\cf13 'z = '\cf6 ,inputs[\cf12 0\cf6 ],\cf13 '*'\cf6 ,\cf11 self\cf6 .weights[\cf12 0\cf6 ], \cf13 '+'\cf6 , inputs[\cf12 1\cf6 ], \cb1 \
\cb3               \cf13 '*'\cf6 , \cf11 self\cf6 .weights[\cf12 1\cf6 ], \cf13 '='\cf6 , z)\cb1 \
\
\cb3         \cf2 #activation\cf6 \cb1 \
\cb3         \cf7 if\cf6  z > \cf12 0\cf6 :\cb1 \
\cb3           activation = \cf12 1\cf6 \cb1 \
\cb3         \cf7 else\cf6 :\cb1 \
\cb3           activation = \cf12 0\cf6             \cb1 \
\cb3         \cf7 return\cf6  activation\cb1 \
\
\cb3     \cf8 def\cf6  \cf10 train\cf6 (\cf11 self\cf6 , \cf11 training_inputs\cf6 , \cf11 labels\cf6 ):\cb1 \
\cb3         \cf7 for\cf6  i \cf8 in\cf6  \cf10 range\cf6 (\cf11 self\cf6 .threshold):\cb1 \
\cb3             \cf10 print\cf6 (\cf13 '--------- Training Iteration: '\cf6 , i, \cf13 '-----------'\cf6 )\cb1 \
\cb3             \cf7 for\cf6  inputs, label \cf8 in\cf6  \cf10 zip\cf6 (training_inputs, labels):\cb1 \
\cb3                 \cf10 print\cf6 (\cf13 'Current inputs, weights, bias: '\cf6 , inputs, \cf13 ' '\cf6 , \cf11 self\cf6 .weights, \cf13 ' '\cf6 , \cf11 self\cf6 .bias)\cb1 \
\cb3                 yhat = \cf11 self\cf6 .predict(inputs)\cb1 \
\cb3                 \cf10 print\cf6 (\cf13 'Activation(yhat) = '\cf6 , yhat)\cb1 \
\cb3                 error = label - yhat\cb1 \
\cb3                 \cf10 print\cf6 (\cf13 'Error = '\cf6 , label, \cf13 '-'\cf6 , yhat, \cf13 '='\cf6 , error)\cb1 \
\cb3                 \cf11 self\cf6 .weights += \cf11 self\cf6 .learning_rate * error * inputs\cb1 \
\cb3                 \cf11 self\cf6 .bias += \cf11 self\cf6 .learning_rate * error\cb1 \
\cb3                 \cf10 print\cf6 (\cf13 'Updated Weights: '\cf6 , \cf11 self\cf6 .weights)\cb1 \
\cb3                 \cf10 print\cf6 (\cf13 'Updated Bias: '\cf6 , \cf11 self\cf6 .bias, \cf13 '\\n'\cf6 )\cb1 \
\
\cf7 \cb3 if\cf6  __name__ == \cf13 '__main__'\cf6 :\cb1 \
\cb3         input_matrix = []\cb1 \
\
\cb3         \cf2 #2-input And gate truth table\cf6 \cb1 \
\cb3         labels = np.array([\cf12 1\cf6 , \cf12 0\cf6 , \cf12 0\cf6 , \cf12 0\cf6 ])         \cf2 #output\cf6 \cb1 \
\cb3         input_matrix.append(np.array([\cf12 1\cf6 , \cf12 1\cf6 ]))   \cf2 #input combinations\cf6 \cb1 \
\cb3         input_matrix.append(np.array([\cf12 1\cf6 , \cf12 0\cf6 ]))\cb1 \
\cb3         input_matrix.append(np.array([\cf12 0\cf6 , \cf12 1\cf6 ]))\cb1 \
\cb3         input_matrix.append(np.array([\cf12 0\cf6 , \cf12 0\cf6 ]))\cb1 \
\
\cb3         \cf2 #2-input or gate truth table\cf6 \cb1 \
\cb3         \cf2 #labels = np.array([1, 1, 1, 0])         #output\cf6 \cb1 \
\cb3         \cf2 #input_matrix.append(np.array([1, 1]))   #input combinations\cf6 \cb1 \
\cb3         \cf2 #input_matrix.append(np.array([1, 0]))\cf6 \cb1 \
\cb3         \cf2 #input_matrix.append(np.array([0, 1]))\cf6 \cb1 \
\cb3         \cf2 #input_matrix.append(np.array([0, 0]))\cf6 \cb1 \
\
\cb3         \cf2 #2-input nand gate truth table\cf6 \cb1 \
\cb3         \cf2 #labels = np.array([0, 1, 1, 1])         #output\cf6 \cb1 \
\cb3         \cf2 #input_matrix.append(np.array([1, 1]))   #input combinations\cf6 \cb1 \
\cb3         \cf2 #input_matrix.append(np.array([1, 0]))\cf6 \cb1 \
\cb3         \cf2 #input_matrix.append(np.array([0, 1]))\cf6 \cb1 \
\cb3         \cf2 #input_matrix.append(np.array([0, 0]))        \cf6 \cb1 \
\
\cb3         \cf2 #Construct Perceptron object (num of inputs, threshold, learning rate)\cf6 \cb1 \
\cb3         perceptron = Perceptron(\cf12 2\cf6 , threshold=\cf12 10\cf6 , learning_rate=\cf12 1\cf6 )\cb1 \
\
\cb3         \cf2 #Train the network\cf6 \cb1 \
\cb3         perceptron.train(input_matrix, labels)\cb1 \
\
\cb3         \cf2 #Test the network \cf6 \cb1 \
\cb3         a = \cf12 1\cf6 \cb1 \
\cb3         b = \cf12 1\cf6 \cb1 \
\cb3         inputs = np.array([a, b])\cb1 \
\cb3         \cf10 print\cf6 (\cf13 '--------- Input ---------'\cf6 , inputs)\cb1 \
\cb3         output = perceptron.predict(inputs)\cb1 \
\cb3         \cf10 print\cf6 (\cf13 '--------- Output --------'\cf6 , output)\cb1 \
\
}